{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    precision_recall_fscore_support,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    accuracy_score  \n",
    ") \n",
    "from sklearn.metrics import precision_recall_curve, auc \n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.pipeline import Pipeline as ImbPipeline \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fraudcreditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ede59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()  #Gives the first 5 rows\n",
    "df.shape  #gives the number of rows and cols\n",
    "# df.info() #gives datatype and memory used\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts to see if data is imbalanced\n",
    "df['Class'].value_counts(normalize='True') #this dataset is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa66968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the class prediction --> Dataset is highly imbalanced\n",
    "plt.figure(figsize=(3,3))\n",
    "df['Class'].value_counts().plot(kind='bar' , color='black')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbacf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3326aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "df[['Amount','Time']] = scaler.fit_transform(df[['Amount','Time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ae6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29946fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "plt.figure(figsize=(3,3))\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "correlation = numeric_df.corr() #df.corr()works only with numeric values hence we consider numeric_df\n",
    "sns.heatmap(correlation , annot = False , cmap = 'coolwarm' , center = 0)\n",
    "plt.title('HeatMap')\n",
    "plt.show()\n",
    "\n",
    "# Features most correlated with churn\n",
    "class_corr = correlation['Class'].sort_values(ascending = True)\n",
    "print(\"Top features correlated with class\")\n",
    "print(class_corr.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0062c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Scale only on training set\n",
    "scaler = StandardScaler()\n",
    "X_train[['Amount','Time']] = scaler.fit_transform(X_train[['Amount','Time']])\n",
    "X_test[['Amount','Time']] = scaler.transform(X_test[['Amount','Time']])\n",
    "\n",
    "# Apply SMOTE on training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# XGBoost\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_clf.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dece4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = log_reg.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "y_pred_pro_lr = log_reg.predict_proba(X_test)[: , 1]\n",
    "y_pred_pro_rf = rf.predict_proba(X_test)[: , 1]\n",
    "y_pred_pro_xgb = xgb_clf.predict_proba(X_test)[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac106c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def eval_models(y_true , y_pred , y_pred_proba , model_name):\n",
    "    print(f\"\\n{ '=' *50}\")\n",
    "    print(f\"{model_name} Results\")\n",
    "    print(f\"{ '=' *50}\")\n",
    "    \n",
    "    #Accuracy\n",
    "    accuracy = accuracy_score(y_true , y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    #ROC-AUC Curve\n",
    "    roc_auc = roc_auc_score(y_true , y_pred)\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    #Confusion Matrix\n",
    "    cm = confusion_matrix(y_true , y_pred)\n",
    "    print(f\"Confusion-Matrix:\\n {cm}\")\n",
    "    \n",
    "    print(f\"Classification Report:\\n {classification_report(y_true , y_pred)}\")\n",
    "    \n",
    "    plt.figure(figsize=(2, 2))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "eval_models(y_test , y_pred_lr , y_pred_pro_lr , \"Logistic Regression\")\n",
    "eval_models(y_test , y_pred_rf , y_pred_pro_rf , \"Random Forest\") \n",
    "eval_models(y_test , y_pred_xgb , y_pred_pro_xgb , \"XGB Model\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39cc1e0",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "1) Logistic Regression shows very low precision.</br>\n",
    " Since it is a linear model, it struggles to separate the classes even after SMOTE.</br>\n",
    " SMOTE helps create balanced training data, but LR still cannot capture the complex patterns needed to correctly identify minority (fraud) cases.</br>\n",
    "</br>\n",
    "4) Random Forest performs well with SMOTE. </br>\n",
    "It achieves a strong balance of precision and recall, meaning it catches many frauds while keeping false alarms low.</br>\n",
    "</br>\n",
    "5) XGBoost performs the best.</br>\n",
    "It learns the synthetic patterns created by SMOTE even more effectively, giving the highest recall and best overall performance (including ROC-AUC).</br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
